{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"results_analysis.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Installing Packages\n","!pip install vaderSentiment"],"metadata":{"id":"Q7ykXxT73N0K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Cloning repository\n","!git clone https://github.com/cpow24/character_relationship_analysis.git"],"metadata":{"id":"tGNSInL8G-v-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Import modules\n","import pandas as pd\n","import numpy as np\n","import sys\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","sys.path.append('character_relationship_analysis/data')\n","\n","sns.set_style('whitegrid', {'axes.linewidth': 1, 'axes.edgecolor':'black'})"],"metadata":{"id":"GiE_0PG1CNzi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Relationship Sentiment Data\n","new_df = pd.read_csv('character_relationship_analysis/data/sentiments_new_model.csv')\n","old_df = pd.read_csv('character_relationship_analysis/data/sentiments_old_model.csv')\n","\n","#Dataframe of shared sentence counts without coref\n","shared_no_coref = pd.read_csv('character_relationship_analysis/data/shared_sentences_no_coref.csv')"],"metadata":{"id":"YjHWrwncCZgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Create dataframe of total interactions captured for each book\n","with and without coreference resolution\n","'''\n","def num_interactions(new_coref_df, old_coref_df, no_coref_df):\n","\n","  int_df = pd.DataFrame(columns=['Title', 'Interactions', 'Type'])\n","  titles = list(np.unique(new_coref_df['title']))\n","  title_list = []\n","  ints = []\n","  types = []\n","  \n","  for title in titles:\n","    int_count_new = new_coref_df[new_coref_df['title'] == title]['pair'].value_counts()\n","    int_count_old = old_coref_df[old_coref_df['title'] == title]['pair'].value_counts()\n","\n","    title_list.append(title)\n","    ints.append(np.sum(int_count_new))\n","    types.append('Char-Coref')\n","    title_list.append(title)\n","    ints.append(np.sum(int_count_old))\n","    types.append('Long-Doc Coref')\n","\n","  int_df['Title'] = title_list\n","  int_df['Interactions'] = ints\n","  int_df['Type'] = types\n","\n","  no_coref_df['Type'] = 'No Coref'\n","  no_coref_df['Interactions'] = no_coref_df['shared_sentences']\n","  no_coref_df['Title'] = no_coref_df['book']\n","\n","  no_coref_df = no_coref_df[['Title', 'Interactions', 'Type']]\n","\n","  int_df = pd.concat([int_df, no_coref_df])\n","\n","  return int_df"],"metadata":{"id":"vktxAb0IU_M7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Dataframe of total interactions\n","interaction_df = num_interactions(new_df, old_df, shared_no_coref)"],"metadata":{"id":"J9iT-e_-XBG8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Plotting interaction counts\n","sns.set_style('whitegrid', {'axes.linewidth': 1, 'axes.edgecolor':'black'})\n","sns.set_palette(sns.color_palette(\"tab10\"))\n","bar_plot = sns.barplot(data=interaction_df, x='Title',y='Interactions', hue='Type')\n","bar_plot.set_xlabel('Book', weight='bold')\n","bar_plot.set_ylabel('Interactions', weight='bold')\n","bar_plot.set_title('Interaction Count - Coref vs No Coref', weight='bold')\n","bar_plot.set_xticklabels(['Ch. & the Choc. Fac', 'Dracula', 'Harry Potter', 'Peter Pan', 'Winnie the Pooh'],rotation = 45,\n","                         horizontalalignment='right')\n","sns.set(rc={\"figure.figsize\":(8, 6)})\n","sns.set(font_scale = 1.4)\n","plt.show()"],"metadata":{"id":"_Gln1Op8gPAY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Function to calculate cumulative sentiment scores\n","and extracts number of interactions per character pair\n","'''\n","def cumulative_sentiment(data):\n","\n","  data.drop_duplicates(subset=['sentence', 'pair', 'sub_sent_vader'], inplace=True)\n","  data.sort_values(by=['pair', 'sent_loc'], inplace=True)\n","\n","  #Cumulative Sentiment - Sub-Sentence\n","  data['vader_sub_sent_cumsum'] = data.groupby('pair')['sub_sent_vader'].cumsum()\n","\n","  #Cumulative Sentiment - Sentence\n","  data['vader_sentence_cumsum'] = data.groupby('pair')['sent_vader'].cumsum()\n","\n","  #Cumulative Sentiment - Verb\n","  data['vader_verb_cumsum'] = data.groupby('pair')['verb_vader'].cumsum()\n","\n","  #Character pair interaction count\n","  int_counts = data['pair'].value_counts()\n","  num_ints_dict = dict(zip(int_counts.index, int_counts))\n","  data['num_ints'] = data['pair'].apply(lambda x: num_ints_dict[x])\n","\n","  return data"],"metadata":{"id":"3qleKYlAIHxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Indicator function for determining whether\n","relationship is in the top 5 in terms of most\n","interactions for a given book\n","'''\n","def top_5(data):\n","  titles = list(np.unique(data['title']))\n","\n","  top_5_list = []\n","  for title in titles:\n","    int_count = data[data['title'] == title]['pair'].value_counts()\n","    book_top_5 = list(int_count.index[:5])\n","    top_5_list.extend(book_top_5)\n","\n","  data['top_5'] = data.apply(lambda x: True if x['pair'] in top_5_list else False, axis=1)\n","\n","  return data"],"metadata":{"id":"95u4tF_43RYd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Processing dataframes\n","new_df = cumulative_sentiment(new_df)\n","old_df = cumulative_sentiment(old_df)\n","new_df = top_5(new_df)\n","old_df = top_5(old_df)"],"metadata":{"id":"5J1WdUQ4TlTk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Creating dataframe for joint plot of sentiment model distributions\n","sentiment_models = pd.DataFrame(columns=['model', 'score'])\n","vader_sent_scores = list(new_df['sub_sent_vader'])\n","model_vader = ['Vader'] * len(vader_sent_scores)\n","roberta_sent_scores = list(new_df['sub_sent_score'])\n","model_roberta = ['RoBERTa'] * len(vader_sent_scores)\n","\n","models = model_vader\n","models.extend(model_roberta)\n","\n","scores = vader_sent_scores\n","scores.extend(roberta_sent_scores)\n","\n","sentiment_models['Model'] = models\n","sentiment_models['score'] = scores"],"metadata":{"id":"X3EjnNVgMWMf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Distribution plots for sentiment analysis model scores\n","sns.set_style('whitegrid', {'axes.linewidth': 1, 'axes.edgecolor':'black'})\n","sns.set_palette(sns.color_palette(\"tab10\"))\n","model_dist = sns.histplot(data=sentiment_models, x='score', hue = 'Model')\n","model_dist.set_xlabel('Sentiment Score', weight='bold')\n","model_dist.set_ylabel('Count', weight='bold')\n","model_dist.set_title('Sentiment Score Distribution', weight='bold')\n","sns.set(rc={\"figure.figsize\":(8, 6)})\n","sns.set(font_scale = 1.4)\n","plt.show()"],"metadata":{"id":"8_q1MJ8dCkak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#New Model Plots - Sub-sentences\n","titles = list(np.unique(new_df['title']))\n","\n","for title in titles:\n","  plot_data = new_df[(new_df['title'] == title) & (new_df['top_5'] == True)]\n","  plot_data.sort_values(by=['pair', 'sent_loc'], inplace=True)\n","\n","  #Cumulative sentiment plots\n","  sns.set_palette(sns.color_palette(\"tab10\"))\n","  sns.set_style('whitegrid', {'axes.linewidth': 1, 'axes.edgecolor':'black'})\n","  model_dist = sns.lineplot(data=plot_data, x = 'sent_loc', y='vader_sub_sent_cumsum', hue = 'pair')\n","  plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n","  model_dist.set(xlabel='Sentence Index', ylabel='Cumulative Sentiment (sub-sentence)', title = f'{title} Relationships - Char-Coref')\n","  sns.set(font_scale = 1.4)\n","  plt.show()"],"metadata":{"id":"ojNcVpjfbEqy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#New Model Plots - Sentences\n","titles = list(np.unique(new_df['title']))\n","\n","for title in titles:\n","  plot_data = new_df[(new_df['title'] == title) & (new_df['top_5'] == True)]\n","  plot_data.sort_values(by=['pair', 'sent_loc'], inplace=True)\n","\n","  #Cumulative sentiment plots\n","  sns.set(font_scale = 1.4)\n","  sns.set_palette(sns.color_palette(\"tab10\"))\n","  sns.set_style('whitegrid', {'axes.linewidth': 1, 'axes.edgecolor':'black'})\n","  model_dist = sns.lineplot(data=plot_data, x = 'sent_loc', y='vader_sentence_cumsum', hue = 'pair')\n","  plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n","  model_dist.set_xlabel('Sentence Index', weight='bold')\n","  model_dist.set_ylabel('Cumulative Sentiment (sentence)', weight='bold')\n","  model_dist.set_title(f'{title} Relationships - Char-Coref', weight='bold')\n","  plt.show()"],"metadata":{"id":"c32EvJ9uFfR4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Old Model Plots - Sub-Sentences\n","titles = list(np.unique(old_df['title']))\n","\n","for title in titles:\n","  plot_data = old_df[(old_df['title'] == title) & (old_df['top_5'] == True)]\n","  plot_data.sort_values(by=['pair', 'sent_loc'], inplace=True)\n","\n","  if title == 'Harry Potter Book 1 - old':\n","    title = 'Harry Potter Book 1'\n","\n","  #Cumulative sentiment plots\n","  sns.set_palette(sns.color_palette(\"tab10\"))\n","  sns.set_style('whitegrid', {'axes.linewidth': 1, 'axes.edgecolor':'black'})\n","  model_dist = sns.lineplot(data=plot_data, x = 'sent_loc', y='vader_sub_sent_cumsum', hue = 'pair')\n","  plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n","  model_dist.set(xlabel='Sentence Index', ylabel='Cumulative Sentiment (sub-sentence)', title = f'{title} Relationships - Long-Doc Coref')\n","  sns.set(font_scale = 1.4)\n","  plt.show()"],"metadata":{"id":"xKRbU5laGklo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Old Model Plots - Sentences\n","titles = list(np.unique(old_df['title']))\n","\n","for title in titles:\n","  plot_data = old_df[(old_df['title'] == title) & (old_df['top_5'] == True)]\n","  plot_data.sort_values(by=['pair', 'sent_loc'], inplace=True)\n","\n","  if title == 'Harry Potter Book 1 - old':\n","    title = 'Harry Potter Book 1'\n","    \n","  #Cumulative sentiment plots\n","  sns.set_palette(sns.color_palette(\"tab10\"))\n","  sns.set_style('whitegrid', {'axes.linewidth': 1, 'axes.edgecolor':'black'})\n","  model_dist = sns.lineplot(data=plot_data, x = 'sent_loc', y='vader_sentence_cumsum', hue = 'pair')\n","  plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n","  model_dist.set(xlabel='Sentence Index', ylabel='Cumulative Sentiment (sentence)', title = f'{title} Relationships - Long-Doc Coref')\n","  sns.set(font_scale = 1.4)\n","  plt.show()"],"metadata":{"id":"U--SDgAWHInY"},"execution_count":null,"outputs":[]}]}